{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Handling in Python\n",
    "---\n",
    "Python is commonly used as the go-to tool for data analysis, especially on larger datasets. Python has many tools and packages available that allow users to gain insights into their data in an efficient manner. In order to use Python for data analysis, we have to learn about the main data handling package, which is the pandas package.\n",
    "\n",
    "pandas is a Python package providing data structures designed to make working with “relational” or “labeled” data simple. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. This lesson will completely focused on thepandas package and understanding the different capabilities and functions that are available to users to assist with data analysis. The lesson will be broken down into 4 parts:\n",
    "1. pandas Basics\n",
    "2. Reading in Data from External Sources\n",
    "3. Working with pandas Dataframes\n",
    "4. Summary Statistics and Numeric Functions in pandas\n",
    "\n",
    "Additionally, users will be exposed to a typical EY use case in which the skills learned through the lesson can be applied to your engagement. Users will develop code to assist with profiling data sets, a common task for data-driven engagements at EY.\n",
    "\n",
    "Overall, this lesson aims to provide users with the knowledge of the fundamental commands that they will need to work with data in Python. Knowledge of the pandas package is the foundation for performing data analysis in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: python-dateutil>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2->pandas)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pandas Basics\n",
    "---\n",
    "In order to use the Pandas package, you will need to import it at the beginning of your script. In the following code, we import the Pandas package and provide it with an alias, \"pd\", which will be used to reference the package in the remainder of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Pandas package has been imported, you are ready to use the functions from this package. First we will demonstrate how to create a Pandas dataframe, and fill it with the numbers 1 through 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "list = [1,2,3,4,5]\n",
    "print(\"Original data type: %s\" % (type(list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created a simple list in python, we can convert this data structure to a Pandas dataframe using the Pandas.DataFrame() function. We see that the data type has changed from a list to a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data type: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#Converting existing list to a Pandas dataframe\n",
    "pandas_list = pd.DataFrame(list)\n",
    "print(\"New data type: %s\" % (type(pandas_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of converting a two-dimensional list to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  1   2\n",
      "0   Jack  1  NY\n",
      "1  Sally  2  CA\n",
      "2  Chris  3  FL\n"
     ]
    }
   ],
   "source": [
    "list_2d = [('Jack', 1, 'NY'), ('Sally', 2, 'CA'), ('Chris', 3, 'FL')]\n",
    "pandas_list_2d = pd.DataFrame(list_2d)\n",
    "print(pandas_list_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reference columns and rows from the Pandas dataframe using indexing. There are two primary functions that can be used to locate records in a pandas dataframe. The first function, the .iloc() function, uses integers to represent rows and columns. The ':' operator can be used to 'select all'. For example, the next instruction prints the first row of data in the pandas dataframe.<br/>\n",
    "<b>(Note: Indexes in pandas dataframes begin at 0)<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0  1   2\n",
      "0  Jack  1  NY\n"
     ]
    }
   ],
   "source": [
    "#Access first row\n",
    "print(pandas_list_2d.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .iloc() to pull a column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Jack\n",
      "1    Sally\n",
      "2    Chris\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Access first column\n",
    "print(pandas_list_2d.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we may want to disply the first n rows of our pandas dataframe. We can use the .head(n) function to print out the first n rows of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0  1   2\n",
      "0   Jack  1  NY\n",
      "1  Sally  2  CA\n"
     ]
    }
   ],
   "source": [
    "#Print first 2 rows\n",
    "print(pandas_list_2d.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the column identifiers of '0' and '1' in the dataframe above are not very prescriptive. Luckily, the pandas package provides us with a method of renaming columns using the .rename() function, which can be seen below. In the next instruction, we rename the columns of our dataframe to 'Name', 'ID' and 'State':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  ID State\n",
      "0   Jack   1    NY\n",
      "1  Sally   2    CA\n",
      "2  Chris   3    FL\n"
     ]
    }
   ],
   "source": [
    "#Rename column\n",
    "pandas_list_2d_rename = pandas_list_2d.rename(columns={0 : 'Name', 1: 'ID', 2 : 'State'})\n",
    "print(pandas_list_2d_rename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have appropriate names for our columns, we can epxlore the second indexing function from the pandas package. The .loc() function relies on the actual row and column identifiers to reference certain records in the pandas dataframe. Below, we are pulling the values from the 'Name' column for all rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Jack\n",
      "1    Sally\n",
      "2    Chris\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Reference columns by new names\n",
    "print(pandas_list_2d_rename.loc[:, 'Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful trick is how to create a new pandas dataframe using columns from an existing pandas dataframe. By using double brackets, we can select columns from a pandas dataframe and assign it to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name State\n",
      "0   Jack    NY\n",
      "1  Sally    CA\n",
      "2  Chris    FL\n"
     ]
    }
   ],
   "source": [
    "#Select the Name and State columns using double brackets\n",
    "new_pandas = pandas_list_2d_rename[['Name', 'State']]\n",
    "print(new_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have manually filled our pandas dataframes in python. However, a much more practical data source is an excel or csv file. Luckily, pandas provides us the tools to read in data from these file formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reading in Data from External Sources\n",
    "---\n",
    "When python is required for data analysis, it is often because there are large amounts of data that need to be analyzed. In order to process these large datasets, pandas provides us with tools to read in data from excel files, csv files, and directly from database connections. \n",
    "\n",
    "First, we will show you how to read in data from an excel file. We will be reading in the customer orders data which is found on the 'Orders' sheet in the 'Superstore.xlsx' file:<br/>\n",
    "<b>(Note: Column names from th excel are automatically recognized by the pandas dataframe)<b/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
      "3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "5          6  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "6          7  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "7          8  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "8          9  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "9         10  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "10        11  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "11        12  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "12        13  CA-2017-114412 2017-04-15 2017-04-20  Standard Class   \n",
      "13        14  CA-2016-161389 2016-12-05 2016-12-10  Standard Class   \n",
      "14        15  US-2015-118983 2015-11-22 2015-11-26  Standard Class   \n",
      "15        16  US-2015-118983 2015-11-22 2015-11-26  Standard Class   \n",
      "16        17  CA-2014-105893 2014-11-11 2014-11-18  Standard Class   \n",
      "17        18  CA-2014-167164 2014-05-13 2014-05-15    Second Class   \n",
      "18        19  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "19        20  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "20        21  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "21        22  CA-2016-137330 2016-12-09 2016-12-13  Standard Class   \n",
      "22        23  CA-2016-137330 2016-12-09 2016-12-13  Standard Class   \n",
      "23        24  US-2017-156909 2017-07-16 2017-07-18    Second Class   \n",
      "24        25  CA-2015-106320 2015-09-25 2015-09-30  Standard Class   \n",
      "25        26  CA-2016-121755 2016-01-16 2016-01-20    Second Class   \n",
      "26        27  CA-2016-121755 2016-01-16 2016-01-20    Second Class   \n",
      "27        28  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "28        29  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "29        30  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "...      ...             ...        ...        ...             ...   \n",
      "9964    9965  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9965    9966  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9966    9967  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9967    9968  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9968    9969  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9969    9970  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9970    9971  CA-2015-103772 2015-06-28 2015-07-02  Standard Class   \n",
      "9971    9972  CA-2015-103772 2015-06-28 2015-07-02  Standard Class   \n",
      "9972    9973  CA-2016-130225 2016-09-11 2016-09-17  Standard Class   \n",
      "9973    9974  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9974    9975  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9975    9976  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9976    9977  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9977    9978  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9978    9979  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9979    9980  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9980    9981  US-2015-151435 2015-09-06 2015-09-09    Second Class   \n",
      "9981    9982  CA-2017-163566 2017-08-03 2017-08-06     First Class   \n",
      "9982    9983  US-2016-157728 2016-09-22 2016-09-28  Standard Class   \n",
      "9983    9984  US-2016-157728 2016-09-22 2016-09-28  Standard Class   \n",
      "9984    9985  CA-2015-100251 2015-05-17 2015-05-23  Standard Class   \n",
      "9985    9986  CA-2015-100251 2015-05-17 2015-05-23  Standard Class   \n",
      "9986    9987  CA-2016-125794 2016-09-29 2016-10-03  Standard Class   \n",
      "9987    9988  CA-2017-163629 2017-11-17 2017-11-21  Standard Class   \n",
      "9988    9989  CA-2017-163629 2017-11-17 2017-11-21  Standard Class   \n",
      "9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
      "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
      "\n",
      "     Customer ID  Customer Name      Segment        Country             City  \\\n",
      "0       CG-12520            NaN     Consumer  United States        Henderson   \n",
      "1       CG-12520            NaN     Consumer  United States        Henderson   \n",
      "2       DV-13045            NaN    Corporate  United States      Los Angeles   \n",
      "3       SO-20335            NaN     Consumer  United States  Fort Lauderdale   \n",
      "4       SO-20335            NaN     Consumer  United States  Fort Lauderdale   \n",
      "5       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "6       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "7       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "8       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "9       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "10      BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "11      BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "12      AA-10480            NaN     Consumer  United States          Concord   \n",
      "13      IM-15070            NaN     Consumer  United States          Seattle   \n",
      "14      HP-14815            NaN  Home Office  United States       Fort Worth   \n",
      "15      HP-14815            NaN  Home Office  United States       Fort Worth   \n",
      "16      PK-19075            NaN     Consumer  United States          Madison   \n",
      "17      AG-10270            NaN     Consumer  United States      West Jordan   \n",
      "18      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "19      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "20      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "21      KB-16585            NaN    Corporate  United States          Fremont   \n",
      "22      KB-16585            NaN    Corporate  United States          Fremont   \n",
      "23      SF-20065            NaN     Consumer  United States     Philadelphia   \n",
      "24      EB-13870            NaN     Consumer  United States             Orem   \n",
      "25      EH-13945            NaN     Consumer  United States      Los Angeles   \n",
      "26      EH-13945            NaN     Consumer  United States      Los Angeles   \n",
      "27      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "28      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "29      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "...          ...            ...          ...            ...              ...   \n",
      "9964    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9965    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9966    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9967    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9968    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9969    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9970    MP-17470            NaN  Home Office  United States           Smyrna   \n",
      "9971    MP-17470            NaN  Home Office  United States           Smyrna   \n",
      "9972    RC-19960            NaN     Consumer  United States          Houston   \n",
      "9973    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9974    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9975    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9976    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9977    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9978    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9979    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9980    SW-20455            NaN     Consumer  United States        Lafayette   \n",
      "9981    TB-21055            NaN     Consumer  United States        Fairfield   \n",
      "9982    RC-19960            NaN     Consumer  United States     Grand Rapids   \n",
      "9983    RC-19960            NaN     Consumer  United States     Grand Rapids   \n",
      "9984    DV-13465            NaN     Consumer  United States       Long Beach   \n",
      "9985    DV-13465            NaN     Consumer  United States       Long Beach   \n",
      "9986    ML-17410            NaN     Consumer  United States      Los Angeles   \n",
      "9987    RA-19885            NaN    Corporate  United States           Athens   \n",
      "9988    RA-19885            NaN    Corporate  United States           Athens   \n",
      "9989    TB-21400            NaN     Consumer  United States            Miami   \n",
      "9990    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9991    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9992    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9993    CC-12220            NaN     Consumer  United States      Westminster   \n",
      "\n",
      "        ...     Postal Code   Region       Product ID         Category  \\\n",
      "0       ...           42420    South  FUR-BO-10001798        Furniture   \n",
      "1       ...           42420    South  FUR-CH-10000454        Furniture   \n",
      "2       ...           90036     West  OFF-LA-10000240  Office Supplies   \n",
      "3       ...           33311    South  FUR-TA-10000577        Furniture   \n",
      "4       ...           33311    South  OFF-ST-10000760  Office Supplies   \n",
      "5       ...           90032     West  FUR-FU-10001487        Furniture   \n",
      "6       ...           90032     West  OFF-AR-10002833  Office Supplies   \n",
      "7       ...           90032     West  TEC-PH-10002275       Technology   \n",
      "8       ...           90032     West  OFF-BI-10003910  Office Supplies   \n",
      "9       ...           90032     West  OFF-AP-10002892  Office Supplies   \n",
      "10      ...           90032     West  FUR-TA-10001539        Furniture   \n",
      "11      ...           90032     West  TEC-PH-10002033       Technology   \n",
      "12      ...           28027    South  OFF-PA-10002365  Office Supplies   \n",
      "13      ...           98103     West  OFF-BI-10003656  Office Supplies   \n",
      "14      ...           76106  Central  OFF-AP-10002311  Office Supplies   \n",
      "15      ...           76106  Central  OFF-BI-10000756  Office Supplies   \n",
      "16      ...           53711  Central  OFF-ST-10004186  Office Supplies   \n",
      "17      ...           84084     West  OFF-ST-10000107  Office Supplies   \n",
      "18      ...           94109     West  OFF-AR-10003056  Office Supplies   \n",
      "19      ...           94109     West  TEC-PH-10001949       Technology   \n",
      "20      ...           94109     West  OFF-BI-10002215  Office Supplies   \n",
      "21      ...           68025  Central  OFF-AR-10000246  Office Supplies   \n",
      "22      ...           68025  Central  OFF-AP-10001492  Office Supplies   \n",
      "23      ...           19140     East  FUR-CH-10002774        Furniture   \n",
      "24      ...           84057     West  FUR-TA-10000577        Furniture   \n",
      "25      ...           90049     West  OFF-BI-10001634  Office Supplies   \n",
      "26      ...           90049     West  TEC-AC-10003027       Technology   \n",
      "27      ...           19140     East  FUR-BO-10004834        Furniture   \n",
      "28      ...           19140     East  OFF-BI-10000474  Office Supplies   \n",
      "29      ...           19140     East  FUR-FU-10004848        Furniture   \n",
      "...     ...             ...      ...              ...              ...   \n",
      "9964    ...           19711     East  FUR-FU-10002671        Furniture   \n",
      "9965    ...           19711     East  OFF-PA-10000349  Office Supplies   \n",
      "9966    ...           19711     East  OFF-EN-10004483  Office Supplies   \n",
      "9967    ...            7060     East  OFF-BI-10004209  Office Supplies   \n",
      "9968    ...            7060     East  OFF-BI-10004600  Office Supplies   \n",
      "9969    ...            7060     East  OFF-AP-10003622  Office Supplies   \n",
      "9970    ...           30080    South  OFF-BI-10002867  Office Supplies   \n",
      "9971    ...           30080    South  OFF-AR-10000538  Office Supplies   \n",
      "9972    ...           77041  Central  OFF-EN-10000056  Office Supplies   \n",
      "9973    ...           90032     West  TEC-PH-10004080       Technology   \n",
      "9974    ...           90032     West  OFF-AR-10004752  Office Supplies   \n",
      "9975    ...           90032     West  OFF-PA-10000743  Office Supplies   \n",
      "9976    ...           90032     West  TEC-PH-10002496       Technology   \n",
      "9977    ...           90032     West  OFF-FA-10003467  Office Supplies   \n",
      "9978    ...           90032     West  OFF-BI-10003727  Office Supplies   \n",
      "9979    ...           90032     West  OFF-BI-10002026  Office Supplies   \n",
      "9980    ...           70506    South  FUR-TA-10001039        Furniture   \n",
      "9981    ...           45014     East  OFF-LA-10004484  Office Supplies   \n",
      "9982    ...           49505  Central  OFF-PA-10002195  Office Supplies   \n",
      "9983    ...           49505  Central  TEC-PH-10001305       Technology   \n",
      "9984    ...           11561     East  OFF-LA-10003766  Office Supplies   \n",
      "9985    ...           11561     East  OFF-SU-10000898  Office Supplies   \n",
      "9986    ...           90008     West  TEC-AC-10003399       Technology   \n",
      "9987    ...           30605    South  TEC-AC-10001539       Technology   \n",
      "9988    ...           30605    South  TEC-PH-10004006       Technology   \n",
      "9989    ...           33180    South  FUR-FU-10001889        Furniture   \n",
      "9990    ...           92627     West  FUR-FU-10000747        Furniture   \n",
      "9991    ...           92627     West  TEC-PH-10003645       Technology   \n",
      "9992    ...           92627     West  OFF-PA-10004041  Office Supplies   \n",
      "9993    ...           92683     West  OFF-AP-10002684  Office Supplies   \n",
      "\n",
      "     Sub-Category                                       Product Name  \\\n",
      "0       Bookcases                  Bush Somerset Collection Bookcase   \n",
      "1          Chairs  Hon Deluxe Fabric Upholstered Stacking Chairs,...   \n",
      "2          Labels  Self-Adhesive Address Labels for Typewriters b...   \n",
      "3          Tables      Bretford CR4500 Series Slim Rectangular Table   \n",
      "4         Storage                     Eldon Fold 'N Roll Cart System   \n",
      "5     Furnishings  Eldon Expressions Wood and Plastic Desk Access...   \n",
      "6             Art                                         Newell 322   \n",
      "7          Phones                     Mitel 5320 IP Phone VoIP phone   \n",
      "8         Binders  DXL Angle-View Binders with Locking Rings by S...   \n",
      "9      Appliances                   Belkin F5C206VTEL 6 Outlet Surge   \n",
      "10         Tables           Chromcraft Rectangular Conference Tables   \n",
      "11         Phones      Konftel 250 Conference phone - Charcoal black   \n",
      "12          Paper                                         Xerox 1967   \n",
      "13        Binders        Fellowes PB200 Plastic Comb Binding Machine   \n",
      "14     Appliances  Holmes Replacement Filter for HEPA Air Cleaner...   \n",
      "15        Binders   Storex DuraTech Recycled Plastic Frosted Binders   \n",
      "16        Storage  Stur-D-Stor Shelving, Vertical 5-Shelf: 72\"H x...   \n",
      "17        Storage                         Fellowes Super Stor/Drawer   \n",
      "18            Art                                         Newell 341   \n",
      "19         Phones                            Cisco SPA 501G IP Phone   \n",
      "20        Binders        Wilson Jones Hanging View Binder, White, 1\"   \n",
      "21            Art                                         Newell 318   \n",
      "22     Appliances        Acco Six-Outlet Power Strip, 4' Cord Length   \n",
      "23         Chairs                 Global Deluxe Stacking Chair, Gray   \n",
      "24         Tables      Bretford CR4500 Series Slim Rectangular Table   \n",
      "25        Binders                    Wilson Jones Active Use Binders   \n",
      "26    Accessories   Imation 8GB Mini TravelDrive USB 2.0 Flash Drive   \n",
      "27      Bookcases  Riverside Palais Royal Lawyers Bookcase, Royal...   \n",
      "28        Binders  Avery Recycled Flexi-View Covers for Binding S...   \n",
      "29    Furnishings  Howard Miller 13-3/4\" Diameter Brushed Chrome ...   \n",
      "...           ...                                                ...   \n",
      "9964  Furnishings  Electrix 20W Halogen Replacement Bulb for Zoom...   \n",
      "9965        Paper                                  Easy-staple paper   \n",
      "9966    Envelopes         #10 White Business Envelopes,4 1/8 x 9 1/2   \n",
      "9967      Binders            Fellowes Twister Kit, Gray/Clear, 3/pkg   \n",
      "9968      Binders          Ibico Ibimaster 300 Manual Binding System   \n",
      "9969   Appliances  Bravo II Megaboss 12-Amp Hard Body Upright, Re...   \n",
      "9970      Binders            GBC Recycled Regency Composition Covers   \n",
      "9971          Art  Boston Model 1800 Electric Pencil Sharpener, Gray   \n",
      "9972    Envelopes                        Cameo Buff Policy Envelopes   \n",
      "9973       Phones                           Avaya 5410 Digital phone   \n",
      "9974          Art                               Blackstonian Pencils   \n",
      "9975        Paper                                         Xerox 1977   \n",
      "9976       Phones                                       Cisco SPA301   \n",
      "9977    Fasteners           Alliance Big Bands Rubber Bands, 12/Pack   \n",
      "9978      Binders  Avery Durable Slant Ring Binders With Label Ho...   \n",
      "9979      Binders                  Ibico Recycled Linen-Style Covers   \n",
      "9980       Tables                         KI Adjustable-Height Table   \n",
      "9981       Labels                                          Avery 476   \n",
      "9982        Paper  RSVP Cards & Envelopes, Blank White, 8-1/2\" X ...   \n",
      "9983       Phones                   Panasonic KX TS208W Corded phone   \n",
      "9984       Labels                     Self-Adhesive Removable Labels   \n",
      "9985     Supplies  Acme Hot Forged Carbon Steel Scissors with Nic...   \n",
      "9986  Accessories  Memorex Mini Travel Drive 64 GB USB 2.0 Flash ...   \n",
      "9987  Accessories  Logitech G430 Surround Sound Gaming Headset wi...   \n",
      "9988       Phones                    Panasonic KX - TS880B Telephone   \n",
      "9989  Furnishings                             Ultra Door Pull Handle   \n",
      "9990  Furnishings  Tenex B1-RE Series Chair Mats for Low Pile Car...   \n",
      "9991       Phones                              Aastra 57i VoIP phone   \n",
      "9992        Paper  It's Hot Message Books with Stickers, 2 3/4\" x 5\"   \n",
      "9993   Appliances  Acco 7-Outlet Masterpiece Power Center, Wihtou...   \n",
      "\n",
      "          Sales  Quantitie  Discount     Profit  \n",
      "0      261.9600        2.0      0.00    41.9136  \n",
      "1      731.9400        3.0      0.00   219.5820  \n",
      "2       14.6200        2.0      0.00     6.8714  \n",
      "3      957.5775        5.0      0.45  -383.0310  \n",
      "4       22.3680        2.0      0.20     2.5164  \n",
      "5       48.8600        7.0      0.00    14.1694  \n",
      "6        7.2800        4.0      0.00     1.9656  \n",
      "7      907.1520        6.0      0.20    90.7152  \n",
      "8       18.5040        3.0      0.20     5.7825  \n",
      "9      114.9000        5.0      0.00    34.4700  \n",
      "10    1706.1840        9.0      0.20    85.3092  \n",
      "11     911.4240        4.0      0.20    68.3568  \n",
      "12      15.5520        3.0      0.20     5.4432  \n",
      "13          NaN        3.0      0.20   132.5922  \n",
      "14      68.8100        5.0      0.80  -123.8580  \n",
      "15       2.5440        3.0      0.80    -3.8160  \n",
      "16     665.8800        6.0       NaN    13.3176  \n",
      "17      55.5000        2.0      0.00     9.9900  \n",
      "18       8.5600        2.0      0.00     2.4824  \n",
      "19     213.4800        NaN      0.20    16.0110  \n",
      "20      22.7200        4.0      0.20     7.3840  \n",
      "21      19.4600        7.0      0.00     5.0596  \n",
      "22      60.3400        7.0      0.00    15.6884  \n",
      "23      71.3720        2.0      0.30    -1.0196  \n",
      "24    1044.6300        NaN      0.00        NaN  \n",
      "25      11.6480        2.0      0.20     4.2224  \n",
      "26      90.5700        3.0      0.00    11.7741  \n",
      "27    3083.4300        7.0      0.50 -1665.0522  \n",
      "28       9.6180        2.0      0.70    -7.0532  \n",
      "29     124.2000        3.0      0.20    15.5250  \n",
      "...         ...        ...       ...        ...  \n",
      "9964    13.4000        1.0      0.00     6.4320  \n",
      "9965     4.9800        1.0      0.00     2.3406  \n",
      "9966   109.6900        7.0      0.00    51.5543  \n",
      "9967    40.2000        5.0      0.00    18.0900  \n",
      "9968   735.9800        2.0      0.00   331.1910  \n",
      "9969    22.7500        7.0      0.00     6.5975  \n",
      "9970   119.5600        2.0      0.00    54.9976  \n",
      "9971   140.7500        5.0      0.00    42.2250  \n",
      "9972    99.5680        2.0      0.20    33.6042  \n",
      "9973   271.9600        5.0      0.20    27.1960  \n",
      "9974    18.6900        7.0      0.00     5.2332  \n",
      "9975    13.3600        2.0      0.00     6.4128  \n",
      "9976   249.5840        2.0      0.20    31.1980  \n",
      "9977    13.8600        7.0      0.00     0.0000  \n",
      "9978    13.3760        4.0      0.20     4.6816  \n",
      "9979   437.4720       14.0      0.20   153.1152  \n",
      "9980    85.9800        1.0      0.00    22.3548  \n",
      "9981    16.5200        5.0      0.20     5.3690  \n",
      "9982    35.5600        7.0      0.00    16.7132  \n",
      "9983    97.9800        2.0      0.00    27.4344  \n",
      "9984    31.5000       10.0      0.00    15.1200  \n",
      "9985    55.6000        4.0      0.00    16.1240  \n",
      "9986    36.2400        1.0      0.00    15.2208  \n",
      "9987    79.9900        1.0      0.00    28.7964  \n",
      "9988   206.1000        5.0      0.00    55.6470  \n",
      "9989    25.2480        3.0      0.20     4.1028  \n",
      "9990    91.9600        2.0      0.00    15.6332  \n",
      "9991   258.5760        2.0      0.20    19.3932  \n",
      "9992    29.6000        4.0      0.00    13.3200  \n",
      "9993   243.1600        2.0      0.00    72.9480  \n",
      "\n",
      "[9994 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "excel_data = pd.read_excel(\"Superstore.xlsx\", sheet_name = 'Orders')\n",
    "print(excel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has specific functions for reading in data from a csv. Here we are reading in the data regarding order returns which has been saved as a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Returned        Order ID\n",
      "0        Yes  CA-2017-153822\n",
      "1        Yes  CA-2017-129707\n",
      "2        Yes  CA-2014-152345\n",
      "3        Yes  CA-2015-156440\n",
      "4        Yes  US-2017-155999\n",
      "5        Yes  CA-2014-157924\n",
      "6        Yes  CA-2017-131807\n",
      "7        Yes  CA-2016-124527\n",
      "8        Yes  CA-2017-135692\n",
      "9        Yes  CA-2014-123225\n",
      "10       Yes  CA-2017-145772\n",
      "11       Yes  US-2014-105137\n",
      "12       Yes  CA-2017-101805\n",
      "13       Yes  CA-2016-111682\n",
      "14       Yes  CA-2017-131492\n",
      "15       Yes  CA-2015-104129\n",
      "16       Yes  CA-2017-117926\n",
      "17       Yes  US-2016-115952\n",
      "18       Yes  CA-2015-155761\n",
      "19       Yes  CA-2017-100111\n",
      "20       Yes  CA-2014-156349\n",
      "21       Yes  CA-2016-118899\n",
      "22       Yes  CA-2017-108294\n",
      "23       Yes  US-2017-123834\n",
      "24       Yes  CA-2015-168480\n",
      "25       Yes  CA-2017-122007\n",
      "26       Yes  CA-2017-128965\n",
      "27       Yes  CA-2015-169397\n",
      "28       Yes  CA-2015-168564\n",
      "29       Yes  CA-2014-102652\n",
      "..       ...             ...\n",
      "266      Yes  CA-2015-149650\n",
      "267      Yes  CA-2014-100867\n",
      "268      Yes  CA-2017-140186\n",
      "269      Yes  CA-2017-156391\n",
      "270      Yes  CA-2015-157770\n",
      "271      Yes  CA-2017-140963\n",
      "272      Yes  CA-2017-154949\n",
      "273      Yes  CA-2016-166275\n",
      "274      Yes  US-2014-143287\n",
      "275      Yes  CA-2014-151162\n",
      "276      Yes  US-2017-103828\n",
      "277      Yes  CA-2014-143840\n",
      "278      Yes  CA-2014-160773\n",
      "279      Yes  CA-2017-111556\n",
      "280      Yes  CA-2017-140585\n",
      "281      Yes  CA-2014-103373\n",
      "282      Yes  CA-2016-159023\n",
      "283      Yes  CA-2016-145492\n",
      "284      Yes  CA-2017-118122\n",
      "285      Yes  CA-2014-116785\n",
      "286      Yes  US-2014-164763\n",
      "287      Yes  CA-2017-122504\n",
      "288      Yes  CA-2017-150910\n",
      "289      Yes  CA-2015-162166\n",
      "290      Yes  US-2016-140172\n",
      "291      Yes  CA-2015-101910\n",
      "292      Yes  CA-2017-156958\n",
      "293      Yes  CA-2016-105585\n",
      "294      Yes  CA-2016-148796\n",
      "295      Yes  CA-2015-149636\n",
      "\n",
      "[296 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_data = pd.read_csv(\"Returns.csv\")\n",
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working with Pandas Dataframes\n",
    "---\n",
    "Now that we have read in our source data, we can begin performing basic operaitons on the datasets. In this section, we will look at performing basic counts, joins, groupbys, and filtering. We will also look at how to change data types of certain columns in our pandas dataframes.\n",
    "\n",
    "First, we show how to perform simple counts on pandas dataframes. We will be using the 'excel_data' datafrane we created in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: \n",
      "Row ID                    int64\n",
      "Order ID                 object\n",
      "Order Date       datetime64[ns]\n",
      "Ship Date        datetime64[ns]\n",
      "Ship Mode                object\n",
      "Customer ID              object\n",
      "Customer Name           float64\n",
      "Segment                  object\n",
      "Country                  object\n",
      "City                     object\n",
      "State                    object\n",
      "Postal Code               int64\n",
      "Region                   object\n",
      "Product ID               object\n",
      "Category                 object\n",
      "Sub-Category             object\n",
      "Product Name             object\n",
      "Sales                   float64\n",
      "Quantitie               float64\n",
      "Discount                float64\n",
      "Profit                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Show the column name and data type for the column\n",
    "print(\"Data Types: \\n%s\" % (excel_data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see all of our fields and their associcated data types, we can begin to perform more complex operations and analysis on our data. However, if we look at the data types of our fields, we notice that the data type for 'Postal Code' is an integer (int64). This may cause issues because zip codes can start with 0's, and may be truncated if the field is an integer. To prevent this from happening, we can manually change the data type of the 'Postal Code' field using the coe below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: \n",
      "Row ID                    int64\n",
      "Order ID                 object\n",
      "Order Date       datetime64[ns]\n",
      "Ship Date        datetime64[ns]\n",
      "Ship Mode                object\n",
      "Customer ID              object\n",
      "Customer Name           float64\n",
      "Segment                  object\n",
      "Country                  object\n",
      "City                     object\n",
      "State                    object\n",
      "Postal Code              object\n",
      "Region                   object\n",
      "Product ID               object\n",
      "Category                 object\n",
      "Sub-Category             object\n",
      "Product Name             object\n",
      "Sales                   float64\n",
      "Quantitie               float64\n",
      "Discount                float64\n",
      "Profit                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Change the data type of the 'Postal Code' field from an integer to an object\n",
    "excel_data[['Postal Code']] = excel_data[['Postal Code']].astype(object)\n",
    "\n",
    "#Show the column name and data type for the column\n",
    "print(\"Data Types: \\n%s\" % (excel_data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 'Postal Code' field is an object, which is the string data type in python.\n",
    "\n",
    "Next, we can begin performing simple counts on our dataframe to find the number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 9994\n"
     ]
    }
   ],
   "source": [
    "#Count of number of rows\n",
    "print(\"Number of rows: %s\" % (len(excel_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 21\n"
     ]
    }
   ],
   "source": [
    "#Count the number of columns\n",
    "print(\"Number of columns: %s\" % (len(excel_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we read in two separate datasets. The first dataframe, excel_data, contained all of our sales data for a store. The second dataframe, csv_data, contained information on orders that were returned. For simplicity moving forward, let us rename these dataframes to more appropriate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign excel_data and csv_data to new pandas dataframes.\n",
    "sales_data = excel_data\n",
    "returns_data = csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a store owner, it would be beneficial for us to know which orders were returned and to have that information stored in a single table. However, we do not to lose any of our sales that were not returned. Pandas allows us to join dataframes together using the .merge() function, much like we are able to do in SQL. If we observe our two dataframes, we see that the 'Order ID' column can be used as a key to join the two dataframes together. That operation and the result is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "0          1  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "1          2  CA-2016-152156 2016-11-08 2016-11-11    Second Class   \n",
      "2          3  CA-2016-138688 2016-06-12 2016-06-16    Second Class   \n",
      "3          4  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "4          5  US-2015-108966 2015-10-11 2015-10-18  Standard Class   \n",
      "5          6  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "6          7  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "7          8  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "8          9  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "9         10  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "10        11  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "11        12  CA-2014-115812 2014-06-09 2014-06-14  Standard Class   \n",
      "12        13  CA-2017-114412 2017-04-15 2017-04-20  Standard Class   \n",
      "13        14  CA-2016-161389 2016-12-05 2016-12-10  Standard Class   \n",
      "14        15  US-2015-118983 2015-11-22 2015-11-26  Standard Class   \n",
      "15        16  US-2015-118983 2015-11-22 2015-11-26  Standard Class   \n",
      "16        17  CA-2014-105893 2014-11-11 2014-11-18  Standard Class   \n",
      "17        18  CA-2014-167164 2014-05-13 2014-05-15    Second Class   \n",
      "18        19  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "19        20  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "20        21  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "21        22  CA-2016-137330 2016-12-09 2016-12-13  Standard Class   \n",
      "22        23  CA-2016-137330 2016-12-09 2016-12-13  Standard Class   \n",
      "23        24  US-2017-156909 2017-07-16 2017-07-18    Second Class   \n",
      "24        25  CA-2015-106320 2015-09-25 2015-09-30  Standard Class   \n",
      "25        26  CA-2016-121755 2016-01-16 2016-01-20    Second Class   \n",
      "26        27  CA-2016-121755 2016-01-16 2016-01-20    Second Class   \n",
      "27        28  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "28        29  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "29        30  US-2015-150630 2015-09-17 2015-09-21  Standard Class   \n",
      "...      ...             ...        ...        ...             ...   \n",
      "9964    9965  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9965    9966  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9966    9967  CA-2016-146374 2016-12-05 2016-12-10    Second Class   \n",
      "9967    9968  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9968    9969  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9969    9970  CA-2017-153871 2017-12-11 2017-12-17  Standard Class   \n",
      "9970    9971  CA-2015-103772 2015-06-28 2015-07-02  Standard Class   \n",
      "9971    9972  CA-2015-103772 2015-06-28 2015-07-02  Standard Class   \n",
      "9972    9973  CA-2016-130225 2016-09-11 2016-09-17  Standard Class   \n",
      "9973    9974  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9974    9975  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9975    9976  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9976    9977  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9977    9978  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9978    9979  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9979    9980  US-2016-103674 2016-12-06 2016-12-10  Standard Class   \n",
      "9980    9981  US-2015-151435 2015-09-06 2015-09-09    Second Class   \n",
      "9981    9982  CA-2017-163566 2017-08-03 2017-08-06     First Class   \n",
      "9982    9983  US-2016-157728 2016-09-22 2016-09-28  Standard Class   \n",
      "9983    9984  US-2016-157728 2016-09-22 2016-09-28  Standard Class   \n",
      "9984    9985  CA-2015-100251 2015-05-17 2015-05-23  Standard Class   \n",
      "9985    9986  CA-2015-100251 2015-05-17 2015-05-23  Standard Class   \n",
      "9986    9987  CA-2016-125794 2016-09-29 2016-10-03  Standard Class   \n",
      "9987    9988  CA-2017-163629 2017-11-17 2017-11-21  Standard Class   \n",
      "9988    9989  CA-2017-163629 2017-11-17 2017-11-21  Standard Class   \n",
      "9989    9990  CA-2014-110422 2014-01-21 2014-01-23    Second Class   \n",
      "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9993    9994  CA-2017-119914 2017-05-04 2017-05-09    Second Class   \n",
      "\n",
      "     Customer ID  Customer Name      Segment        Country             City  \\\n",
      "0       CG-12520            NaN     Consumer  United States        Henderson   \n",
      "1       CG-12520            NaN     Consumer  United States        Henderson   \n",
      "2       DV-13045            NaN    Corporate  United States      Los Angeles   \n",
      "3       SO-20335            NaN     Consumer  United States  Fort Lauderdale   \n",
      "4       SO-20335            NaN     Consumer  United States  Fort Lauderdale   \n",
      "5       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "6       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "7       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "8       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "9       BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "10      BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "11      BH-11710            NaN     Consumer  United States      Los Angeles   \n",
      "12      AA-10480            NaN     Consumer  United States          Concord   \n",
      "13      IM-15070            NaN     Consumer  United States          Seattle   \n",
      "14      HP-14815            NaN  Home Office  United States       Fort Worth   \n",
      "15      HP-14815            NaN  Home Office  United States       Fort Worth   \n",
      "16      PK-19075            NaN     Consumer  United States          Madison   \n",
      "17      AG-10270            NaN     Consumer  United States      West Jordan   \n",
      "18      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "19      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "20      ZD-21925            NaN     Consumer  United States    San Francisco   \n",
      "21      KB-16585            NaN    Corporate  United States          Fremont   \n",
      "22      KB-16585            NaN    Corporate  United States          Fremont   \n",
      "23      SF-20065            NaN     Consumer  United States     Philadelphia   \n",
      "24      EB-13870            NaN     Consumer  United States             Orem   \n",
      "25      EH-13945            NaN     Consumer  United States      Los Angeles   \n",
      "26      EH-13945            NaN     Consumer  United States      Los Angeles   \n",
      "27      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "28      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "29      TB-21520            NaN     Consumer  United States     Philadelphia   \n",
      "...          ...            ...          ...            ...              ...   \n",
      "9964    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9965    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9966    HE-14800            NaN    Corporate  United States           Newark   \n",
      "9967    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9968    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9969    RB-19435            NaN     Consumer  United States       Plainfield   \n",
      "9970    MP-17470            NaN  Home Office  United States           Smyrna   \n",
      "9971    MP-17470            NaN  Home Office  United States           Smyrna   \n",
      "9972    RC-19960            NaN     Consumer  United States          Houston   \n",
      "9973    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9974    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9975    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9976    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9977    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9978    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9979    AP-10720            NaN  Home Office  United States      Los Angeles   \n",
      "9980    SW-20455            NaN     Consumer  United States        Lafayette   \n",
      "9981    TB-21055            NaN     Consumer  United States        Fairfield   \n",
      "9982    RC-19960            NaN     Consumer  United States     Grand Rapids   \n",
      "9983    RC-19960            NaN     Consumer  United States     Grand Rapids   \n",
      "9984    DV-13465            NaN     Consumer  United States       Long Beach   \n",
      "9985    DV-13465            NaN     Consumer  United States       Long Beach   \n",
      "9986    ML-17410            NaN     Consumer  United States      Los Angeles   \n",
      "9987    RA-19885            NaN    Corporate  United States           Athens   \n",
      "9988    RA-19885            NaN    Corporate  United States           Athens   \n",
      "9989    TB-21400            NaN     Consumer  United States            Miami   \n",
      "9990    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9991    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9992    DB-13060            NaN     Consumer  United States       Costa Mesa   \n",
      "9993    CC-12220            NaN     Consumer  United States      Westminster   \n",
      "\n",
      "        ...      Region       Product ID         Category Sub-Category  \\\n",
      "0       ...       South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       ...       South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       ...        West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       ...       South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       ...       South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "5       ...        West  FUR-FU-10001487        Furniture  Furnishings   \n",
      "6       ...        West  OFF-AR-10002833  Office Supplies          Art   \n",
      "7       ...        West  TEC-PH-10002275       Technology       Phones   \n",
      "8       ...        West  OFF-BI-10003910  Office Supplies      Binders   \n",
      "9       ...        West  OFF-AP-10002892  Office Supplies   Appliances   \n",
      "10      ...        West  FUR-TA-10001539        Furniture       Tables   \n",
      "11      ...        West  TEC-PH-10002033       Technology       Phones   \n",
      "12      ...       South  OFF-PA-10002365  Office Supplies        Paper   \n",
      "13      ...        West  OFF-BI-10003656  Office Supplies      Binders   \n",
      "14      ...     Central  OFF-AP-10002311  Office Supplies   Appliances   \n",
      "15      ...     Central  OFF-BI-10000756  Office Supplies      Binders   \n",
      "16      ...     Central  OFF-ST-10004186  Office Supplies      Storage   \n",
      "17      ...        West  OFF-ST-10000107  Office Supplies      Storage   \n",
      "18      ...        West  OFF-AR-10003056  Office Supplies          Art   \n",
      "19      ...        West  TEC-PH-10001949       Technology       Phones   \n",
      "20      ...        West  OFF-BI-10002215  Office Supplies      Binders   \n",
      "21      ...     Central  OFF-AR-10000246  Office Supplies          Art   \n",
      "22      ...     Central  OFF-AP-10001492  Office Supplies   Appliances   \n",
      "23      ...        East  FUR-CH-10002774        Furniture       Chairs   \n",
      "24      ...        West  FUR-TA-10000577        Furniture       Tables   \n",
      "25      ...        West  OFF-BI-10001634  Office Supplies      Binders   \n",
      "26      ...        West  TEC-AC-10003027       Technology  Accessories   \n",
      "27      ...        East  FUR-BO-10004834        Furniture    Bookcases   \n",
      "28      ...        East  OFF-BI-10000474  Office Supplies      Binders   \n",
      "29      ...        East  FUR-FU-10004848        Furniture  Furnishings   \n",
      "...     ...         ...              ...              ...          ...   \n",
      "9964    ...        East  FUR-FU-10002671        Furniture  Furnishings   \n",
      "9965    ...        East  OFF-PA-10000349  Office Supplies        Paper   \n",
      "9966    ...        East  OFF-EN-10004483  Office Supplies    Envelopes   \n",
      "9967    ...        East  OFF-BI-10004209  Office Supplies      Binders   \n",
      "9968    ...        East  OFF-BI-10004600  Office Supplies      Binders   \n",
      "9969    ...        East  OFF-AP-10003622  Office Supplies   Appliances   \n",
      "9970    ...       South  OFF-BI-10002867  Office Supplies      Binders   \n",
      "9971    ...       South  OFF-AR-10000538  Office Supplies          Art   \n",
      "9972    ...     Central  OFF-EN-10000056  Office Supplies    Envelopes   \n",
      "9973    ...        West  TEC-PH-10004080       Technology       Phones   \n",
      "9974    ...        West  OFF-AR-10004752  Office Supplies          Art   \n",
      "9975    ...        West  OFF-PA-10000743  Office Supplies        Paper   \n",
      "9976    ...        West  TEC-PH-10002496       Technology       Phones   \n",
      "9977    ...        West  OFF-FA-10003467  Office Supplies    Fasteners   \n",
      "9978    ...        West  OFF-BI-10003727  Office Supplies      Binders   \n",
      "9979    ...        West  OFF-BI-10002026  Office Supplies      Binders   \n",
      "9980    ...       South  FUR-TA-10001039        Furniture       Tables   \n",
      "9981    ...        East  OFF-LA-10004484  Office Supplies       Labels   \n",
      "9982    ...     Central  OFF-PA-10002195  Office Supplies        Paper   \n",
      "9983    ...     Central  TEC-PH-10001305       Technology       Phones   \n",
      "9984    ...        East  OFF-LA-10003766  Office Supplies       Labels   \n",
      "9985    ...        East  OFF-SU-10000898  Office Supplies     Supplies   \n",
      "9986    ...        West  TEC-AC-10003399       Technology  Accessories   \n",
      "9987    ...       South  TEC-AC-10001539       Technology  Accessories   \n",
      "9988    ...       South  TEC-PH-10004006       Technology       Phones   \n",
      "9989    ...       South  FUR-FU-10001889        Furniture  Furnishings   \n",
      "9990    ...        West  FUR-FU-10000747        Furniture  Furnishings   \n",
      "9991    ...        West  TEC-PH-10003645       Technology       Phones   \n",
      "9992    ...        West  OFF-PA-10004041  Office Supplies        Paper   \n",
      "9993    ...        West  OFF-AP-10002684  Office Supplies   Appliances   \n",
      "\n",
      "                                           Product Name      Sales Quantitie  \\\n",
      "0                     Bush Somerset Collection Bookcase   261.9600       2.0   \n",
      "1     Hon Deluxe Fabric Upholstered Stacking Chairs,...   731.9400       3.0   \n",
      "2     Self-Adhesive Address Labels for Typewriters b...    14.6200       2.0   \n",
      "3         Bretford CR4500 Series Slim Rectangular Table   957.5775       5.0   \n",
      "4                        Eldon Fold 'N Roll Cart System    22.3680       2.0   \n",
      "5     Eldon Expressions Wood and Plastic Desk Access...    48.8600       7.0   \n",
      "6                                            Newell 322     7.2800       4.0   \n",
      "7                        Mitel 5320 IP Phone VoIP phone   907.1520       6.0   \n",
      "8     DXL Angle-View Binders with Locking Rings by S...    18.5040       3.0   \n",
      "9                      Belkin F5C206VTEL 6 Outlet Surge   114.9000       5.0   \n",
      "10             Chromcraft Rectangular Conference Tables  1706.1840       9.0   \n",
      "11        Konftel 250 Conference phone - Charcoal black   911.4240       4.0   \n",
      "12                                           Xerox 1967    15.5520       3.0   \n",
      "13          Fellowes PB200 Plastic Comb Binding Machine        NaN       3.0   \n",
      "14    Holmes Replacement Filter for HEPA Air Cleaner...    68.8100       5.0   \n",
      "15     Storex DuraTech Recycled Plastic Frosted Binders     2.5440       3.0   \n",
      "16    Stur-D-Stor Shelving, Vertical 5-Shelf: 72\"H x...   665.8800       6.0   \n",
      "17                           Fellowes Super Stor/Drawer    55.5000       2.0   \n",
      "18                                           Newell 341     8.5600       2.0   \n",
      "19                              Cisco SPA 501G IP Phone   213.4800       NaN   \n",
      "20          Wilson Jones Hanging View Binder, White, 1\"    22.7200       4.0   \n",
      "21                                           Newell 318    19.4600       7.0   \n",
      "22          Acco Six-Outlet Power Strip, 4' Cord Length    60.3400       7.0   \n",
      "23                   Global Deluxe Stacking Chair, Gray    71.3720       2.0   \n",
      "24        Bretford CR4500 Series Slim Rectangular Table  1044.6300       NaN   \n",
      "25                      Wilson Jones Active Use Binders    11.6480       2.0   \n",
      "26     Imation 8GB Mini TravelDrive USB 2.0 Flash Drive    90.5700       3.0   \n",
      "27    Riverside Palais Royal Lawyers Bookcase, Royal...  3083.4300       7.0   \n",
      "28    Avery Recycled Flexi-View Covers for Binding S...     9.6180       2.0   \n",
      "29    Howard Miller 13-3/4\" Diameter Brushed Chrome ...   124.2000       3.0   \n",
      "...                                                 ...        ...       ...   \n",
      "9964  Electrix 20W Halogen Replacement Bulb for Zoom...    13.4000       1.0   \n",
      "9965                                  Easy-staple paper     4.9800       1.0   \n",
      "9966         #10 White Business Envelopes,4 1/8 x 9 1/2   109.6900       7.0   \n",
      "9967            Fellowes Twister Kit, Gray/Clear, 3/pkg    40.2000       5.0   \n",
      "9968          Ibico Ibimaster 300 Manual Binding System   735.9800       2.0   \n",
      "9969  Bravo II Megaboss 12-Amp Hard Body Upright, Re...    22.7500       7.0   \n",
      "9970            GBC Recycled Regency Composition Covers   119.5600       2.0   \n",
      "9971  Boston Model 1800 Electric Pencil Sharpener, Gray   140.7500       5.0   \n",
      "9972                        Cameo Buff Policy Envelopes    99.5680       2.0   \n",
      "9973                           Avaya 5410 Digital phone   271.9600       5.0   \n",
      "9974                               Blackstonian Pencils    18.6900       7.0   \n",
      "9975                                         Xerox 1977    13.3600       2.0   \n",
      "9976                                       Cisco SPA301   249.5840       2.0   \n",
      "9977           Alliance Big Bands Rubber Bands, 12/Pack    13.8600       7.0   \n",
      "9978  Avery Durable Slant Ring Binders With Label Ho...    13.3760       4.0   \n",
      "9979                  Ibico Recycled Linen-Style Covers   437.4720      14.0   \n",
      "9980                         KI Adjustable-Height Table    85.9800       1.0   \n",
      "9981                                          Avery 476    16.5200       5.0   \n",
      "9982  RSVP Cards & Envelopes, Blank White, 8-1/2\" X ...    35.5600       7.0   \n",
      "9983                   Panasonic KX TS208W Corded phone    97.9800       2.0   \n",
      "9984                     Self-Adhesive Removable Labels    31.5000      10.0   \n",
      "9985  Acme Hot Forged Carbon Steel Scissors with Nic...    55.6000       4.0   \n",
      "9986  Memorex Mini Travel Drive 64 GB USB 2.0 Flash ...    36.2400       1.0   \n",
      "9987  Logitech G430 Surround Sound Gaming Headset wi...    79.9900       1.0   \n",
      "9988                    Panasonic KX - TS880B Telephone   206.1000       5.0   \n",
      "9989                             Ultra Door Pull Handle    25.2480       3.0   \n",
      "9990  Tenex B1-RE Series Chair Mats for Low Pile Car...    91.9600       2.0   \n",
      "9991                              Aastra 57i VoIP phone   258.5760       2.0   \n",
      "9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"    29.6000       4.0   \n",
      "9993  Acco 7-Outlet Masterpiece Power Center, Wihtou...   243.1600       2.0   \n",
      "\n",
      "      Discount     Profit  Returned  \n",
      "0         0.00    41.9136       NaN  \n",
      "1         0.00   219.5820       NaN  \n",
      "2         0.00     6.8714       NaN  \n",
      "3         0.45  -383.0310       NaN  \n",
      "4         0.20     2.5164       NaN  \n",
      "5         0.00    14.1694       NaN  \n",
      "6         0.00     1.9656       NaN  \n",
      "7         0.20    90.7152       NaN  \n",
      "8         0.20     5.7825       NaN  \n",
      "9         0.00    34.4700       NaN  \n",
      "10        0.20    85.3092       NaN  \n",
      "11        0.20    68.3568       NaN  \n",
      "12        0.20     5.4432       NaN  \n",
      "13        0.20   132.5922       NaN  \n",
      "14        0.80  -123.8580       NaN  \n",
      "15        0.80    -3.8160       NaN  \n",
      "16         NaN    13.3176       NaN  \n",
      "17        0.00     9.9900       NaN  \n",
      "18        0.00     2.4824       Yes  \n",
      "19        0.20    16.0110       Yes  \n",
      "20        0.20     7.3840       Yes  \n",
      "21        0.00     5.0596       NaN  \n",
      "22        0.00    15.6884       NaN  \n",
      "23        0.30    -1.0196       NaN  \n",
      "24        0.00        NaN       NaN  \n",
      "25        0.20     4.2224       NaN  \n",
      "26        0.00    11.7741       NaN  \n",
      "27        0.50 -1665.0522       NaN  \n",
      "28        0.70    -7.0532       NaN  \n",
      "29        0.20    15.5250       NaN  \n",
      "...        ...        ...       ...  \n",
      "9964      0.00     6.4320       NaN  \n",
      "9965      0.00     2.3406       NaN  \n",
      "9966      0.00    51.5543       NaN  \n",
      "9967      0.00    18.0900       NaN  \n",
      "9968      0.00   331.1910       NaN  \n",
      "9969      0.00     6.5975       NaN  \n",
      "9970      0.00    54.9976       NaN  \n",
      "9971      0.00    42.2250       NaN  \n",
      "9972      0.20    33.6042       NaN  \n",
      "9973      0.20    27.1960       NaN  \n",
      "9974      0.00     5.2332       NaN  \n",
      "9975      0.00     6.4128       NaN  \n",
      "9976      0.20    31.1980       NaN  \n",
      "9977      0.00     0.0000       NaN  \n",
      "9978      0.20     4.6816       NaN  \n",
      "9979      0.20   153.1152       NaN  \n",
      "9980      0.00    22.3548       NaN  \n",
      "9981      0.20     5.3690       NaN  \n",
      "9982      0.00    16.7132       NaN  \n",
      "9983      0.00    27.4344       NaN  \n",
      "9984      0.00    15.1200       NaN  \n",
      "9985      0.00    16.1240       NaN  \n",
      "9986      0.00    15.2208       NaN  \n",
      "9987      0.00    28.7964       NaN  \n",
      "9988      0.00    55.6470       NaN  \n",
      "9989      0.20     4.1028       NaN  \n",
      "9990      0.00    15.6332       Yes  \n",
      "9991      0.20    19.3932       Yes  \n",
      "9992      0.00    13.3200       Yes  \n",
      "9993      0.00    72.9480       NaN  \n",
      "\n",
      "[9994 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#Left join the sales_data to the returns_data on Order ID\n",
    "combined_df = pd.merge(sales_data, returns_data, how = 'left', on = 'Order ID')\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, we did not want to lose any of the sales data for orders that were NOT returned. Consequently, we see many NaN values in our new column, which signifies that the order was not returned. To clean this up, pandas provides a function, .fillna(), that will allow us to replace these values with 'No' instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156 2016-11-08 2016-11-11    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156 2016-11-08 2016-11-11    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688 2016-06-12 2016-06-16    Second Class    DV-13045   \n",
      "3       4  US-2015-108966 2015-10-11 2015-10-18  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966 2015-10-11 2015-10-18  Standard Class    SO-20335   \n",
      "\n",
      "   Customer Name    Segment        Country             City    ...    Region  \\\n",
      "0            NaN   Consumer  United States        Henderson    ...     South   \n",
      "1            NaN   Consumer  United States        Henderson    ...     South   \n",
      "2            NaN  Corporate  United States      Los Angeles    ...      West   \n",
      "3            NaN   Consumer  United States  Fort Lauderdale    ...     South   \n",
      "4            NaN   Consumer  United States  Fort Lauderdale    ...     South   \n",
      "\n",
      "        Product ID         Category Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales Quantitie  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600       2.0   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400       3.0   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200       2.0   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775       5.0   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680       2.0   \n",
      "\n",
      "   Discount    Profit  Returned  \n",
      "0      0.00   41.9136        No  \n",
      "1      0.00  219.5820        No  \n",
      "2      0.00    6.8714        No  \n",
      "3      0.45 -383.0310        No  \n",
      "4      0.20    2.5164        No  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#Fill the NaN values in the 'Returned' column with the value 'No'\n",
    "combined_df['Returned'] = combined_df['Returned'].fillna('No')\n",
    "print(combined_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Now we see that the NaN values in our 'Returned' column have been replaced with 'No'.\n",
    "\n",
    "Next, we can look at all of the orders that were returned to see if there were any similarities between these orders. In order to do this, we need to create a dataframe that contains only the orders that were returned. We can leverage the .loc() function and boolean logic to identify these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Row ID        Order ID Order Date  Ship Date       Ship Mode  \\\n",
      "18        19  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "19        20  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "20        21  CA-2014-143336 2014-08-27 2014-09-01    Second Class   \n",
      "55        56  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "56        57  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "57        58  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "58        59  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "59        60  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "60        61  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "61        62  CA-2016-111682 2016-06-17 2016-06-18     First Class   \n",
      "89        90  CA-2016-109806 2016-09-17 2016-09-22  Standard Class   \n",
      "90        91  CA-2016-109806 2016-09-17 2016-09-22  Standard Class   \n",
      "91        92  CA-2016-109806 2016-09-17 2016-09-22  Standard Class   \n",
      "133      134  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "134      135  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "135      136  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "136      137  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "137      138  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "138      139  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "139      140  CA-2016-145583 2016-10-13 2016-10-19  Standard Class   \n",
      "201      202  CA-2014-133690 2014-08-03 2014-08-05     First Class   \n",
      "202      203  CA-2014-133690 2014-08-03 2014-08-05     First Class   \n",
      "212      213  CA-2015-146262 2015-01-02 2015-01-09  Standard Class   \n",
      "213      214  CA-2015-146262 2015-01-02 2015-01-09  Standard Class   \n",
      "214      215  CA-2015-146262 2015-01-02 2015-01-09  Standard Class   \n",
      "215      216  CA-2015-146262 2015-01-02 2015-01-09  Standard Class   \n",
      "216      217  CA-2015-146262 2015-01-02 2015-01-09  Standard Class   \n",
      "219      220  CA-2015-169397 2015-12-24 2015-12-27     First Class   \n",
      "220      221  CA-2015-169397 2015-12-24 2015-12-27     First Class   \n",
      "221      222  CA-2015-169397 2015-12-24 2015-12-27     First Class   \n",
      "...      ...             ...        ...        ...             ...   \n",
      "9708    9709  CA-2016-161746 2016-10-21 2016-10-27  Standard Class   \n",
      "9709    9710  CA-2016-161746 2016-10-21 2016-10-27  Standard Class   \n",
      "9726    9727  CA-2017-167395 2017-12-02 2017-12-04     First Class   \n",
      "9727    9728  CA-2017-167395 2017-12-02 2017-12-04     First Class   \n",
      "9728    9729  CA-2017-167395 2017-12-02 2017-12-04     First Class   \n",
      "9768    9769  CA-2017-142328 2017-12-07 2017-12-14  Standard Class   \n",
      "9774    9775  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9775    9776  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9776    9777  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9777    9778  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9778    9779  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9779    9780  CA-2014-169019 2014-07-26 2014-07-30  Standard Class   \n",
      "9822    9823  US-2014-164406 2014-08-15 2014-08-19  Standard Class   \n",
      "9823    9824  US-2014-164406 2014-08-15 2014-08-19  Standard Class   \n",
      "9824    9825  US-2014-164406 2014-08-15 2014-08-19  Standard Class   \n",
      "9825    9826  US-2014-164406 2014-08-15 2014-08-19  Standard Class   \n",
      "9826    9827  US-2014-164406 2014-08-15 2014-08-19  Standard Class   \n",
      "9846    9847  CA-2017-169327 2017-09-02 2017-09-04    Second Class   \n",
      "9847    9848  CA-2017-169327 2017-09-02 2017-09-04    Second Class   \n",
      "9848    9849  CA-2017-169327 2017-09-02 2017-09-04    Second Class   \n",
      "9952    9953  CA-2015-141593 2015-12-14 2015-12-16    Second Class   \n",
      "9953    9954  CA-2015-141593 2015-12-14 2015-12-16    Second Class   \n",
      "9954    9955  CA-2015-141593 2015-12-14 2015-12-16    Second Class   \n",
      "9955    9956  CA-2015-141593 2015-12-14 2015-12-16    Second Class   \n",
      "9956    9957  US-2014-143287 2014-11-11 2014-11-17  Standard Class   \n",
      "9957    9958  US-2014-143287 2014-11-11 2014-11-17  Standard Class   \n",
      "9958    9959  US-2014-143287 2014-11-11 2014-11-17  Standard Class   \n",
      "9990    9991  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9991    9992  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "9992    9993  CA-2017-121258 2017-02-26 2017-03-03  Standard Class   \n",
      "\n",
      "     Customer ID  Customer Name      Segment        Country           City  \\\n",
      "18      ZD-21925            NaN     Consumer  United States  San Francisco   \n",
      "19      ZD-21925            NaN     Consumer  United States  San Francisco   \n",
      "20      ZD-21925            NaN     Consumer  United States  San Francisco   \n",
      "55      TB-21055            NaN     Consumer  United States           Troy   \n",
      "56      TB-21055            NaN     Consumer  United States           Troy   \n",
      "57      TB-21055            NaN     Consumer  United States           Troy   \n",
      "58      TB-21055            NaN     Consumer  United States           Troy   \n",
      "59      TB-21055            NaN     Consumer  United States           Troy   \n",
      "60      TB-21055            NaN     Consumer  United States           Troy   \n",
      "61      TB-21055            NaN     Consumer  United States           Troy   \n",
      "89      JS-15685            NaN    Corporate  United States    Los Angeles   \n",
      "90      JS-15685            NaN    Corporate  United States    Los Angeles   \n",
      "91      JS-15685            NaN    Corporate  United States    Los Angeles   \n",
      "133     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "134     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "135     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "136     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "137     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "138     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "139     LC-16885            NaN     Consumer  United States      Roseville   \n",
      "201     BS-11755            NaN     Consumer  United States         Denver   \n",
      "202     BS-11755            NaN     Consumer  United States         Denver   \n",
      "212     VW-21775            NaN    Corporate  United States         Medina   \n",
      "213     VW-21775            NaN    Corporate  United States         Medina   \n",
      "214     VW-21775            NaN    Corporate  United States         Medina   \n",
      "215     VW-21775            NaN    Corporate  United States         Medina   \n",
      "216     VW-21775            NaN    Corporate  United States         Medina   \n",
      "219     JB-15925            NaN     Consumer  United States         Dublin   \n",
      "220     JB-15925            NaN     Consumer  United States         Dublin   \n",
      "221     JB-15925            NaN     Consumer  United States         Dublin   \n",
      "...          ...            ...          ...            ...            ...   \n",
      "9708    CS-11950            NaN     Consumer  United States    Los Angeles   \n",
      "9709    CS-11950            NaN     Consumer  United States    Los Angeles   \n",
      "9726    KM-16720            NaN     Consumer  United States         Lowell   \n",
      "9727    KM-16720            NaN     Consumer  United States         Lowell   \n",
      "9728    KM-16720            NaN     Consumer  United States         Lowell   \n",
      "9768    TC-21535            NaN  Home Office  United States  San Francisco   \n",
      "9774    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9775    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9776    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9777    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9778    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9779    LF-17185            NaN     Consumer  United States    San Antonio   \n",
      "9822    BD-11605            NaN     Consumer  United States  San Francisco   \n",
      "9823    BD-11605            NaN     Consumer  United States  San Francisco   \n",
      "9824    BD-11605            NaN     Consumer  United States  San Francisco   \n",
      "9825    BD-11605            NaN     Consumer  United States  San Francisco   \n",
      "9826    BD-11605            NaN     Consumer  United States  San Francisco   \n",
      "9846    MH-17290            NaN  Home Office  United States    Los Angeles   \n",
      "9847    MH-17290            NaN  Home Office  United States    Los Angeles   \n",
      "9848    MH-17290            NaN  Home Office  United States    Los Angeles   \n",
      "9952    DB-12970            NaN    Corporate  United States    Los Angeles   \n",
      "9953    DB-12970            NaN    Corporate  United States    Los Angeles   \n",
      "9954    DB-12970            NaN    Corporate  United States    Los Angeles   \n",
      "9955    DB-12970            NaN    Corporate  United States    Los Angeles   \n",
      "9956    KN-16705            NaN  Home Office  United States   New Rochelle   \n",
      "9957    KN-16705            NaN  Home Office  United States   New Rochelle   \n",
      "9958    KN-16705            NaN  Home Office  United States   New Rochelle   \n",
      "9990    DB-13060            NaN     Consumer  United States     Costa Mesa   \n",
      "9991    DB-13060            NaN     Consumer  United States     Costa Mesa   \n",
      "9992    DB-13060            NaN     Consumer  United States     Costa Mesa   \n",
      "\n",
      "        ...      Region       Product ID         Category Sub-Category  \\\n",
      "18      ...        West  OFF-AR-10003056  Office Supplies          Art   \n",
      "19      ...        West  TEC-PH-10001949       Technology       Phones   \n",
      "20      ...        West  OFF-BI-10002215  Office Supplies      Binders   \n",
      "55      ...        East  OFF-ST-10000604  Office Supplies      Storage   \n",
      "56      ...        East  OFF-PA-10001569  Office Supplies        Paper   \n",
      "57      ...        East  FUR-CH-10003968        Furniture       Chairs   \n",
      "58      ...        East  OFF-PA-10000587  Office Supplies        Paper   \n",
      "59      ...        East  TEC-AC-10002167       Technology  Accessories   \n",
      "60      ...        East  OFF-BI-10001460  Office Supplies      Binders   \n",
      "61      ...        East  OFF-AR-10001868  Office Supplies          Art   \n",
      "89      ...        West  OFF-AR-10004930  Office Supplies          Art   \n",
      "90      ...        West  TEC-PH-10004093       Technology       Phones   \n",
      "91      ...        West  OFF-PA-10000304  Office Supplies        Paper   \n",
      "133     ...        West  OFF-PA-10001804  Office Supplies        Paper   \n",
      "134     ...        West  OFF-PA-10001736  Office Supplies        Paper   \n",
      "135     ...        West  OFF-AR-10001149  Office Supplies          Art   \n",
      "136     ...        West  OFF-FA-10002988  Office Supplies    Fasteners   \n",
      "137     ...        West  OFF-BI-10004781  Office Supplies      Binders   \n",
      "138     ...        West  OFF-SU-10001218  Office Supplies     Supplies   \n",
      "139     ...        West  FUR-FU-10001706        Furniture  Furnishings   \n",
      "201     ...        West  FUR-TA-10004289        Furniture       Tables   \n",
      "202     ...        West  OFF-AP-10003622  Office Supplies   Appliances   \n",
      "212     ...        East  OFF-LA-10004544  Office Supplies       Labels   \n",
      "213     ...        East  FUR-BO-10004695        Furniture    Bookcases   \n",
      "214     ...        East  TEC-PH-10002844       Technology       Phones   \n",
      "215     ...        East  TEC-MA-10000864       Technology     Machines   \n",
      "216     ...        East  TEC-AC-10000109       Technology  Accessories   \n",
      "219     ...        East  OFF-FA-10000585  Office Supplies    Fasteners   \n",
      "220     ...        East  OFF-PA-10004000  Office Supplies        Paper   \n",
      "221     ...        East  OFF-BI-10002852  Office Supplies      Binders   \n",
      "...     ...         ...              ...              ...          ...   \n",
      "9708    ...        West  FUR-FU-10003731        Furniture  Furnishings   \n",
      "9709    ...        West  OFF-ST-10002743  Office Supplies      Storage   \n",
      "9726    ...        East  OFF-AP-10001293  Office Supplies   Appliances   \n",
      "9727    ...        East  TEC-PH-10004977       Technology       Phones   \n",
      "9728    ...        East  OFF-SU-10001935  Office Supplies     Supplies   \n",
      "9768    ...        West  OFF-PA-10000380  Office Supplies        Paper   \n",
      "9774    ...     Central  OFF-BI-10004995  Office Supplies      Binders   \n",
      "9775    ...     Central  FUR-FU-10004666        Furniture  Furnishings   \n",
      "9776    ...     Central  OFF-BI-10001524  Office Supplies      Binders   \n",
      "9777    ...     Central  TEC-AC-10002076       Technology  Accessories   \n",
      "9778    ...     Central  OFF-BI-10001679  Office Supplies      Binders   \n",
      "9779    ...     Central  OFF-AP-10003281  Office Supplies   Appliances   \n",
      "9822    ...        West  OFF-AP-10003287  Office Supplies   Appliances   \n",
      "9823    ...        West  OFF-PA-10000167  Office Supplies        Paper   \n",
      "9824    ...        West  OFF-BI-10002309  Office Supplies      Binders   \n",
      "9825    ...        West  OFF-BI-10003638  Office Supplies      Binders   \n",
      "9826    ...        West  FUR-CH-10003833        Furniture       Chairs   \n",
      "9846    ...        West  OFF-AP-10001492  Office Supplies   Appliances   \n",
      "9847    ...        West  FUR-FU-10004188        Furniture  Furnishings   \n",
      "9848    ...        West  OFF-BI-10004330  Office Supplies      Binders   \n",
      "9952    ...        West  OFF-BI-10001153  Office Supplies      Binders   \n",
      "9953    ...        West  OFF-PA-10004983  Office Supplies        Paper   \n",
      "9954    ...        West  OFF-BI-10000948  Office Supplies      Binders   \n",
      "9955    ...        West  FUR-TA-10002622        Furniture       Tables   \n",
      "9956    ...        East  OFF-PA-10001776  Office Supplies        Paper   \n",
      "9957    ...        East  OFF-PA-10004039  Office Supplies        Paper   \n",
      "9958    ...        East  OFF-SU-10001574  Office Supplies     Supplies   \n",
      "9990    ...        West  FUR-FU-10000747        Furniture  Furnishings   \n",
      "9991    ...        West  TEC-PH-10003645       Technology       Phones   \n",
      "9992    ...        West  OFF-PA-10004041  Office Supplies        Paper   \n",
      "\n",
      "                                           Product Name     Sales Quantitie  \\\n",
      "18                                           Newell 341     8.560       2.0   \n",
      "19                              Cisco SPA 501G IP Phone   213.480       NaN   \n",
      "20          Wilson Jones Hanging View Binder, White, 1\"    22.720       4.0   \n",
      "55                      Home/Office Personal File Carts   208.560       6.0   \n",
      "56                                            Xerox 232    32.400       5.0   \n",
      "57                             Novimex Turbo Task Chair   319.410       5.0   \n",
      "58               Array Parchment Paper, Assorted Colors    14.560       2.0   \n",
      "59    Imation 8gb Micro Traveldrive Usb 2.0 Flash Drive    30.000       2.0   \n",
      "60                                Plastic Binding Combs    48.480       4.0   \n",
      "61                          Prang Dustless Chalk Sticks     1.680       1.0   \n",
      "89               Turquoise Lead Holder with Pocket Clip    20.100       3.0   \n",
      "90                                   Panasonic Kx-TS550    73.584       2.0   \n",
      "91                                           Xerox 1995     6.480       1.0   \n",
      "133                                           Xerox 195    20.040       3.0   \n",
      "134                                          Xerox 1880    35.440       1.0   \n",
      "135           Sanford Colorific Colored Pencils, 12/Box    11.520       4.0   \n",
      "136                                        Ideal Clamps     4.020       2.0   \n",
      "137                             GBC Wire Binding Strips    76.176       3.0   \n",
      "138                           Fiskars Softgrip Scissors    65.880       6.0   \n",
      "139                        Longer-Life Soft White Bulbs    43.120      14.0   \n",
      "201   BoxOffice By Design Rectangular and Half-Moon ...   218.750       2.0   \n",
      "202   Bravo II Megaboss 12-Amp Hard Body Upright, Re...     2.600       1.0   \n",
      "212                                           Avery 505    23.680       2.0   \n",
      "213   O'Sullivan 2-Door Barrister Bookcase in Odessa...   452.450       5.0   \n",
      "214                 Speck Products Candyshell Flip Case    62.982       3.0   \n",
      "215                  Cisco 9971 IP Video Phone Charcoal  1188.000       9.0   \n",
      "216    Sony Micro Vault Click 16 GB USB 2.0 Flash Drive    89.584       2.0   \n",
      "219                    OIC Bulk Pack Metal Binder Clips     5.584       2.0   \n",
      "220   While You Were Out Pads, 50 per Pad, 4 x 5 1/4...    22.704       6.0   \n",
      "221                   Ibico Standard Transparent Covers    19.776       4.0   \n",
      "...                                                 ...       ...       ...   \n",
      "9708  Eldon Expressions Wood and Plastic Desk Access...    19.960       2.0   \n",
      "9709                      SAFCO Boltless Steel Shelving   340.920       3.0   \n",
      "9726                    Belkin 8 Outlet Surge Protector   286.860       7.0   \n",
      "9727                                        GE 30524EE4   979.950       5.0   \n",
      "9728                                     Staple remover     4.360       2.0   \n",
      "9768  REDIFORM Incoming/Outgoing Call Register, 11\" ...    50.040       6.0   \n",
      "9774          GBC DocuBind P400 Electric Binding System  2177.584       8.0   \n",
      "9775                     DAX Clear Channel Poster Frame    17.496       3.0   \n",
      "9776  GBC Premium Transparent Covers with Diagonal L...    16.784       4.0   \n",
      "9777                   Microsoft Natural Keyboard Elite   431.136       9.0   \n",
      "9778       GBC Instant Index System for Binding Systems     8.880       5.0   \n",
      "9779   Acco 6 Outlet Guardian Standard Surge Suppressor     4.836       2.0   \n",
      "9822  Tripp Lite TLP810NET Broadband Surge for Modem...   152.910       3.0   \n",
      "9823                                         Xerox 1925    92.940       3.0   \n",
      "9824    Avery Heavy-Duty EZD  Binder With Locking Rings    17.856       4.0   \n",
      "9825                         GBC Durable Plastic Covers    46.440       3.0   \n",
      "9826                          Novimex Fabric Task Chair   195.136       4.0   \n",
      "9846        Acco Six-Outlet Power Strip, 4' Cord Length    43.100       5.0   \n",
      "9847       Luxo Professional Combination Clamp-On Lamps   511.500       5.0   \n",
      "9848  GBC Velobind Prepunched Cover Sets, Regency Se...   147.920       5.0   \n",
      "9952               Ibico Recycled Grain-Textured Covers    55.264       2.0   \n",
      "9953                                           Xerox 23     6.480       1.0   \n",
      "9954  GBC Laser Imprintable Binding System Covers, D...    34.248       3.0   \n",
      "9955  Bush Andora Conference Table, Maple/Graphite G...   273.568       2.0   \n",
      "9956  Wirebound Message Books, Four 2 3/4\" x 5\" Form...    46.350       5.0   \n",
      "9957                                         Xerox 1882   223.920       4.0   \n",
      "9958                           Acme Value Line Scissors     7.300       2.0   \n",
      "9990  Tenex B1-RE Series Chair Mats for Low Pile Car...    91.960       2.0   \n",
      "9991                              Aastra 57i VoIP phone   258.576       2.0   \n",
      "9992  It's Hot Message Books with Stickers, 2 3/4\" x 5\"    29.600       4.0   \n",
      "\n",
      "      Discount     Profit  Returned  \n",
      "18         0.0     2.4824       Yes  \n",
      "19         0.2    16.0110       Yes  \n",
      "20         0.2     7.3840       Yes  \n",
      "55         0.0    52.1400       Yes  \n",
      "56         0.0    15.5520       Yes  \n",
      "57         0.1     7.0980       Yes  \n",
      "58         0.0     6.9888       Yes  \n",
      "59         0.0     3.3000       Yes  \n",
      "60         0.2    16.3620       Yes  \n",
      "61         0.0     0.8400       Yes  \n",
      "89         0.0     6.6330       Yes  \n",
      "90         0.2     8.2782       Yes  \n",
      "91         0.0     3.1104       Yes  \n",
      "133        0.0     9.6192       Yes  \n",
      "134        0.0    16.6568       Yes  \n",
      "135        0.0     3.4560       Yes  \n",
      "136        0.0     1.9698       Yes  \n",
      "137        0.2    26.6616       Yes  \n",
      "138        0.0    18.4464       Yes  \n",
      "139        0.0    20.6976       Yes  \n",
      "201        0.5  -161.8750       Yes  \n",
      "202        0.2     0.2925       Yes  \n",
      "212        0.2     8.8800       Yes  \n",
      "213        0.5  -244.3230       Yes  \n",
      "214        0.4   -14.6958       Yes  \n",
      "215        0.7  -950.4000       Yes  \n",
      "216        0.2     4.4792       Yes  \n",
      "219        0.2     1.8148       Yes  \n",
      "220        0.2     8.2302       Yes  \n",
      "221        0.7   -13.8432       Yes  \n",
      "...        ...        ...       ...  \n",
      "9708       0.0     5.5888       Yes  \n",
      "9709       0.0     3.4092       Yes  \n",
      "9726       0.0    80.3208       Yes  \n",
      "9727       0.0   284.1855       Yes  \n",
      "9728       0.0     0.1744       Yes  \n",
      "9768       0.0    25.0200       Yes  \n",
      "9774       0.8 -3701.8928       Yes  \n",
      "9775       0.6   -10.0602       Yes  \n",
      "9776       0.8   -26.8544       Yes  \n",
      "9777       0.2   -26.9460       Yes  \n",
      "9778       0.8   -13.3200       Yes  \n",
      "9779       0.8   -12.0900       Yes  \n",
      "9822       0.0    42.8148       Yes  \n",
      "9823       0.0    41.8230       Yes  \n",
      "9824       0.2     6.2496       Yes  \n",
      "9825       0.2    15.0930       Yes  \n",
      "9826       0.2   -12.1960       Yes  \n",
      "9846       0.0    11.2060       Yes  \n",
      "9847       0.0   132.9900       Yes  \n",
      "9848       0.2    46.2250       Yes  \n",
      "9952       0.2    20.7240       Yes  \n",
      "9953       0.0     3.1104       Yes  \n",
      "9954       0.2    11.5587       Yes  \n",
      "9955       0.2    10.2588       Yes  \n",
      "9956       0.0    21.7845       Yes  \n",
      "9957       0.0   109.7208       Yes  \n",
      "9958       0.0     2.1900       Yes  \n",
      "9990       0.0    15.6332       Yes  \n",
      "9991       0.2    19.3932       Yes  \n",
      "9992       0.0    13.3200       Yes  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#Select all order records where the order was returned.\n",
    "returned_orders_data = combined_df.loc[combined_df['Returned'] == 'Yes']\n",
    "print(returned_orders_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the records in the returned_orders_data dataframe have a value of 'Yes' in the 'Returned' column. \n",
    "\n",
    "We would like to save this information down in a csv for later use by using the pandas .to_csv() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save returned_orders_data to a csv file.\n",
    "returned_orders_data.to_csv(\"returned_orders_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check your current working directory, you will see that this new csv file has been created.\n",
    "\n",
    "If you would like to save a pandas dataframe to Excel, the process is slightly more complicated. You would need to use the pandas .ExcelWriter() function and the pandas .to_excel() function to output to an Excel. The code for this process is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string variable that contains the name of the Excel file. If this file has not been created, python will create it\n",
    "# for you.\n",
    "outfile = \"to_excel_test.xlsx\"\n",
    "\n",
    "# Create an ExcelWriter object using the file name variable you created above.\n",
    "excel_writer = pd.ExcelWriter(outfile) \n",
    "\n",
    "#Write the pandas dataframe to Excel using the to_excel() function. The arguments passed are as follows: \n",
    "# .to_excel(ExcelWriter object, String sheetname, index = False). Setting index = False removes row numbers created by pandas.\n",
    "returned_orders_data.to_excel(excel_writer, \"Completeness Testing\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this step, we have concluded the lesson on basic pandas dataframe operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "1. Create a new pandas dataframe using the columns 'Order ID' and 'Region' from the dataframe 'excel_data' above.\n",
    "2. Print the first 10 records of this new dataframe.\n",
    "3. Print all records where the 'Region' = 'West'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataframe\n",
      "         Order ID Region\n",
      "0  CA-2016-152156  South\n",
      "1  CA-2016-152156  South\n",
      "2  CA-2016-138688   West\n",
      "3  US-2015-108966  South\n",
      "4  US-2015-108966  South\n",
      "5  CA-2014-115812   West\n",
      "6  CA-2014-115812   West\n",
      "7  CA-2014-115812   West\n",
      "8  CA-2014-115812   West\n",
      "9  CA-2014-115812   West\n",
      "West Only Dataframe\n",
      "            Order ID Region\n",
      "2     CA-2016-138688   West\n",
      "5     CA-2014-115812   West\n",
      "6     CA-2014-115812   West\n",
      "7     CA-2014-115812   West\n",
      "8     CA-2014-115812   West\n",
      "9     CA-2014-115812   West\n",
      "10    CA-2014-115812   West\n",
      "11    CA-2014-115812   West\n",
      "13    CA-2016-161389   West\n",
      "17    CA-2014-167164   West\n",
      "18    CA-2014-143336   West\n",
      "19    CA-2014-143336   West\n",
      "20    CA-2014-143336   West\n",
      "24    CA-2015-106320   West\n",
      "25    CA-2016-121755   West\n",
      "26    CA-2016-121755   West\n",
      "42    CA-2016-101343   West\n",
      "62    CA-2015-135545   West\n",
      "63    CA-2015-135545   West\n",
      "64    CA-2015-135545   West\n",
      "65    CA-2015-135545   West\n",
      "67    CA-2014-106376   West\n",
      "68    CA-2014-106376   West\n",
      "81    CA-2014-139451   West\n",
      "82    CA-2014-139451   West\n",
      "89    CA-2016-109806   West\n",
      "90    CA-2016-109806   West\n",
      "91    CA-2016-109806   West\n",
      "95    US-2017-109484   West\n",
      "97    CA-2017-157833   West\n",
      "...              ...    ...\n",
      "9910  US-2015-129007   West\n",
      "9912  CA-2015-132388   West\n",
      "9913  CA-2015-132388   West\n",
      "9928  CA-2016-129630   West\n",
      "9929  CA-2016-129630   West\n",
      "9930  CA-2015-104948   West\n",
      "9931  CA-2015-104948   West\n",
      "9932  CA-2015-104948   West\n",
      "9937  CA-2016-164889   West\n",
      "9941  CA-2017-164028   West\n",
      "9942  CA-2014-143371   West\n",
      "9943  CA-2014-143371   West\n",
      "9944  CA-2015-145415   West\n",
      "9952  CA-2015-141593   West\n",
      "9953  CA-2015-141593   West\n",
      "9954  CA-2015-141593   West\n",
      "9955  CA-2015-141593   West\n",
      "9959  CA-2017-137421   West\n",
      "9973  US-2016-103674   West\n",
      "9974  US-2016-103674   West\n",
      "9975  US-2016-103674   West\n",
      "9976  US-2016-103674   West\n",
      "9977  US-2016-103674   West\n",
      "9978  US-2016-103674   West\n",
      "9979  US-2016-103674   West\n",
      "9986  CA-2016-125794   West\n",
      "9990  CA-2017-121258   West\n",
      "9991  CA-2017-121258   West\n",
      "9992  CA-2017-121258   West\n",
      "9993  CA-2017-119914   West\n",
      "\n",
      "[3203 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "new_df = excel_data[['Order ID', 'Region']]\n",
    "print(\"Original Dataframe\")\n",
    "print(new_df.head(10))\n",
    "\n",
    "west_df = new_df.loc[new_df['Region'] == 'West']\n",
    "print(\"West Only Dataframe\")\n",
    "print(west_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Statistics and Numeric Functions in Pandas\n",
    "---\n",
    "At this point, you should have a basic understanding of how to work with pandas dataframes. Once you feel comfortable with the material above, you can start performing analysis on your data. For this section, we will use the 'returned_orders_data' dataframe that we created in the previous lesson.\n",
    "\n",
    "Pandas provides a great function, the .describe() function, that outputs generic summary statistical information for the NUMERIC fields in our dataframe. Its use is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantitie</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>798.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4799.993750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.163777</td>\n",
       "      <td>3.817272</td>\n",
       "      <td>0.143425</td>\n",
       "      <td>29.048405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2940.248858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620.555988</td>\n",
       "      <td>2.231951</td>\n",
       "      <td>0.197839</td>\n",
       "      <td>296.584600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3701.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2114.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.727000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4929.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.970000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.791200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7162.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>218.226500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>30.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9993.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13999.960000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6719.980800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Row ID  Customer Name         Sales   Quantitie    Discount  \\\n",
       "count   800.000000            0.0    798.000000  799.000000  800.000000   \n",
       "mean   4799.993750            NaN    226.163777    3.817272    0.143425   \n",
       "std    2940.248858            NaN    620.555988    2.231951    0.197839   \n",
       "min      19.000000            NaN      1.680000    1.000000    0.000000   \n",
       "25%    2114.750000            NaN     20.727000    2.000000    0.000000   \n",
       "50%    4929.500000            NaN     59.970000    3.000000    0.000000   \n",
       "75%    7162.750000            NaN    218.226500    5.000000    0.200000   \n",
       "max    9993.000000            NaN  13999.960000   14.000000    0.800000   \n",
       "\n",
       "            Profit  \n",
       "count   793.000000  \n",
       "mean     29.048405  \n",
       "std     296.584600  \n",
       "min   -3701.892800  \n",
       "25%       2.956800  \n",
       "50%      10.791200  \n",
       "75%      30.445000  \n",
       "max    6719.980800  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output summary statistics on numeric columns in returned_orders_data.\n",
    "returned_orders_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .describe() function computes the count, mean, min, max, quartile values, and standard deviation for the numeric columns in our dataframe. This is extremely useful for quick analysis on your data.\n",
    "\n",
    "While this is helpful, it is more common that we may want to perform these calculations on a subset of our data. The next set of instructions demonstrate the use of the individual statistical functions on our dataset. We will be performing these calculations on the 'Sales' column for all returned orders from the West region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 220.199741\n",
      "\n",
      "Std: 705.275995\n",
      "\n",
      "Min: 1.872000\n",
      "\n",
      "25th Percentile: 20.723000\n",
      "\n",
      "50th Percentile: 57.230000\n",
      "\n",
      "75th Percentile: 214.572500\n",
      "\n",
      "Max: 13999.960000\n"
     ]
    }
   ],
   "source": [
    "mean = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].mean()\n",
    "\n",
    "std = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].std()\n",
    "\n",
    "min_value = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].min()\n",
    "\n",
    "perc_25 = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].quantile(.25)\n",
    "\n",
    "perc_50 = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].quantile(.5)\n",
    "\n",
    "perc_75 = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].quantile(.75)\n",
    "\n",
    "max_value = returned_orders_data['Sales'].loc[returned_orders_data['Region'] == 'West'].max()\n",
    "\n",
    "print(\"Mean: %f\\n\" % (mean))\n",
    "print(\"Std: %f\\n\" % (std))\n",
    "print(\"Min: %f\\n\" % (min_value))\n",
    "print(\"25th Percentile: %f\\n\" % (perc_25))\n",
    "print(\"50th Percentile: %f\\n\" % (perc_50))\n",
    "print(\"75th Percentile: %f\\n\" % (perc_75))\n",
    "print(\"Max: %f\" % (max_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, another useful pandas function to know is the .groupby() function. This is a common command used in SQL, and is very important for data analysis. For example, we can use the pandas groupby function to calculate the total return amount for each region by summing the sales amounts and using the groupby function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region\n",
      "Central     14006.9794\n",
      "East        41705.1440\n",
      "South       17309.0970\n",
      "West       107457.4735\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "region_return_amt = returned_orders_data.groupby(['Region'])['Sales'].sum()\n",
    "print(region_return_amt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results, we see the total sales for each region for orders that were returned.\n",
    "\n",
    "We can also groupby multiple columns. For example, if we want to see the same breakdown by region and category, we would use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region   Category       \n",
      "Central  Furniture           4011.1744\n",
      "         Office Supplies     6705.1260\n",
      "         Technology          3290.6790\n",
      "East     Furniture          13812.7820\n",
      "         Office Supplies     7836.1920\n",
      "         Technology         20056.1700\n",
      "South    Furniture           6519.0740\n",
      "         Office Supplies     4583.5010\n",
      "         Technology          6206.5220\n",
      "West     Furniture          34876.1445\n",
      "         Office Supplies    29426.5260\n",
      "         Technology         43154.8030\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "region_cat_return_amt = returned_orders_data.groupby(['Region', 'Category'])['Sales'].sum()\n",
    "print(region_cat_return_amt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use function is the .value_counts() function which allows us to compute the count of unique values in a column in a pandas dataframe, which is very useful when trying to profile a dataset. We can also choose if we would like the function to consider NULL values using the 'dropna' argument. The .value_counts() function returns a series. Sample code is show below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   State  Count\n",
      "0             California   2001\n",
      "1               New York   1128\n",
      "2                  Texas    985\n",
      "3           Pennsylvania    587\n",
      "4             Washington    506\n",
      "5               Illinois    492\n",
      "6                   Ohio    469\n",
      "7                Florida    383\n",
      "8               Michigan    255\n",
      "9         North Carolina    249\n",
      "10              Virginia    224\n",
      "11               Arizona    224\n",
      "12               Georgia    184\n",
      "13             Tennessee    183\n",
      "14              Colorado    182\n",
      "15               Indiana    149\n",
      "16              Kentucky    139\n",
      "17         Massachusetts    135\n",
      "18            New Jersey    130\n",
      "19                Oregon    124\n",
      "20             Wisconsin    110\n",
      "21              Maryland    105\n",
      "22              Delaware     96\n",
      "23             Minnesota     89\n",
      "24           Connecticut     82\n",
      "25              Oklahoma     66\n",
      "26              Missouri     66\n",
      "27               Alabama     61\n",
      "28              Arkansas     60\n",
      "29          Rhode Island     56\n",
      "30           Mississippi     53\n",
      "31                  Utah     53\n",
      "32             Louisiana     42\n",
      "33        South Carolina     42\n",
      "34                Nevada     39\n",
      "35              Nebraska     38\n",
      "36            New Mexico     37\n",
      "37                  Iowa     30\n",
      "38         New Hampshire     27\n",
      "39                Kansas     24\n",
      "40                 Idaho     21\n",
      "41               Montana     15\n",
      "42          South Dakota     12\n",
      "43               Vermont     11\n",
      "44  District of Columbia     10\n",
      "45                 Maine      8\n",
      "46          North Dakota      7\n",
      "47         West Virginia      4\n",
      "48               Wyoming      1\n"
     ]
    }
   ],
   "source": [
    "#Running .value_counts() function.\n",
    "value_counts = combined_df['State'].value_counts(dropna = False)\n",
    "\n",
    "#Additional code for converting results from series to pandas dataframe.\n",
    "count_results = pd.DataFrame({'State':value_counts.index, 'Count':value_counts.values})\n",
    "count_results = count_results[['State', 'Count']]\n",
    "\n",
    "print(count_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the lesson material for the data handling course. The following section will contain an actual business case that leverages the material that you learned in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### EY Use Case: Data profiling\n",
    "---\n",
    "A common task that may benefit from the use of python is data profiling. When we begin projects and are provided with a large dataset, it is often very helpful to provide a summary of the data that you have received.\n",
    "\n",
    "In this exercise, you will be provided with two datasets, one stored as an excel and the other as a csv. You will need to read in these two datasets and join them together. Next, you will notice that two of the columns need to have their names corrected, as they are spelled incorrectly. Then you will need to check to ensure that the data types are correct for all fields. Finally, you will perform profiling on the numeric fields and the categorical fields. \n",
    "<ol>\n",
    "    <li> For the numeric fields, we expect all of the summary information provided by the describe function, but broken down by each date. Additionally, we would also like a count of the NULL values, and a column that shows the percent of records that are populated with non-NULL values. </li>\n",
    "    <li> For the categorical fields, we would like to see a breakdown of the count of each distinct value for each run date. Please save the results in two separate csv files. </li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Leverage the data in the 'combined_df' dataframe. The 'Quantitie' column is spelled incorrectly. Please fix this. Change the datatype of the 'Row ID' field from an integer to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row ID                   object\n",
      "Order ID                 object\n",
      "Order Date       datetime64[ns]\n",
      "Ship Date        datetime64[ns]\n",
      "Ship Mode                object\n",
      "Customer ID              object\n",
      "Customer Name           float64\n",
      "Segment                  object\n",
      "Country                  object\n",
      "City                     object\n",
      "State                    object\n",
      "Postal Code              object\n",
      "Region                   object\n",
      "Product ID               object\n",
      "Category                 object\n",
      "Sub-Category             object\n",
      "Product Name             object\n",
      "Sales                   float64\n",
      "Quantity                float64\n",
      "Discount                float64\n",
      "Profit                  float64\n",
      "Returned                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Change the data type of the 'Row ID' field from an integer to an object\n",
    "combined_df[['Row ID']] = combined_df[['Row ID']].astype(object)\n",
    "\n",
    "#Rename column\n",
    "combined_df = combined_df.rename(columns={'Quantitie' : 'Quantity'})\n",
    "print(combined_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Perform completeness testing on dataset. Identify the total number of records, the count of NULL values, and the percentage of records that is complete for each field. Results should be saved in a single excel file. <br/> <br/> (Note: We will need to find some way to cycle through all of the fields in the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"competeness_testing.xlsx\"\n",
    "writer = pd.ExcelWriter(outfile) \n",
    "\n",
    "#Total record count\n",
    "num_rows = len(combined_df)\n",
    "\n",
    "flag = 0\n",
    "for column in combined_df:\n",
    "    #field_name, total_records, null_count, %_populated\n",
    "    null_ct = combined_df[column].isnull().sum()\n",
    "    pop = 1 - (null_ct / num_rows)\n",
    "    pop = \"{:.2%}\".format(pop)\n",
    "    \n",
    "    results = pd.DataFrame({'FIELD_NAME' : [column], 'TOTAL_POPULATION' : [num_rows], 'NULL_COUNT' : [null_ct], '%_POPULATED' : [pop]})\n",
    "    results = results[[\"FIELD_NAME\", \"TOTAL_POPULATION\",  \"NULL_COUNT\", \"%_POPULATED\"]]\n",
    "\n",
    "    if flag == 0:\n",
    "        final_df = results\n",
    "        flag = 1\n",
    "    else:\n",
    "        final_df = final_df.append(results)\n",
    "       \n",
    "final_df.to_excel(writer, \"Completeness Testing\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Perform attribute profiling on the numeric fields. Please compute the count, mean, minimum value, 25th percentile value, 50th percentile value, 75th percentile value, maximum value, standard deviation, count of NULL values, and count of negative values for each numeric field (integers and floats). Results should be saved in a single excel file.<br/> <br/>\n",
    "(Note: You may receive an 'All-NaN axis encountered' warning from python because one of the columns is completely blank. However, the code will still successfully run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "num_outfile = \"numeric_profiling.xlsx\"\n",
    "num_writer = pd.ExcelWriter(num_outfile)\n",
    "flag = 0\n",
    "for column in combined_df:\n",
    "    if combined_df[column].dtype == 'int64' or combined_df[column].dtype == 'float64':\n",
    "        max_val = np.nanmax(combined_df[column])\n",
    "        min_val = np.nanmin(combined_df[column])\n",
    "        mean = np.mean(combined_df[column])\n",
    "        mean = \"%.2f\" % mean\n",
    "        std = np.std(combined_df[column])\n",
    "        std = \"%.2f\" % std\n",
    "        # May want to use .nanpercentile but 300x slower than percentile\n",
    "        per_25 = np.nanpercentile(combined_df[column], 25)\n",
    "        per_50 = np.nanpercentile(combined_df[column], 50)\n",
    "        per_75 = np.nanpercentile(combined_df[column], 75)\n",
    "        neg_ct = combined_df[column].lt(0).sum()\n",
    "        null_ct = combined_df[column].isnull().sum()\n",
    "        \n",
    "        results = pd.DataFrame({'FIELD_NAME' : [column], \"NUM_ROWS\" : [num_rows], 'MEAN' : [mean], 'MIN' : [min_val], '25%' : [per_25], '50%' : [per_50], '75%' : [per_75], 'MAX' : [max_val], 'STD' : [std], 'NULL_CT' : [null_ct], 'NEG_CT' : [neg_ct]})\n",
    "        results = results[[\"FIELD_NAME\", \"NUM_ROWS\", \"MEAN\",  \"MIN\", \"25%\", \"50%\", \"75%\", \"MAX\", \"STD\", \"NULL_CT\", \"NEG_CT\"]]\n",
    "\n",
    "        if flag == 0:\n",
    "            final_df = results\n",
    "            flag = 1\n",
    "        else:\n",
    "            final_df = final_df.append(results)\n",
    "       \n",
    "final_df.to_excel(num_writer, \"Numeric Profiling\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Perform profiling of categorical attributes. This will be done by computing a count of each unique value in the field. The results of each column should be saved to an individual sheet in an excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_outfile = \"categorical_profiling.xlsx\"\n",
    "cat_writer = pd.ExcelWriter(cat_outfile)\n",
    "flag = 0\n",
    "for column in combined_df:\n",
    "    if combined_df[column].dtype != 'int64' and combined_df[column].dtype != 'float64':\n",
    "        results = combined_df[column].value_counts(dropna = False)\n",
    "        final_df = pd.DataFrame({column:results.index, 'Count':results.values})\n",
    "        final_df = final_df[[column, 'Count']]\n",
    "        final_df.set_index(column, inplace = True)\n",
    "        final_df.to_excel(cat_writer, column[:31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the lesson on Data Handling. Users have learned the basics of the pandas package in Python and can leverage these skills to begin developing more complicated scripts. To summarize, the following topics were covered:\n",
    "1. pandas Basics\n",
    "2. Reading in Data from External Sources\n",
    "3. Working with pandas Dataframes\n",
    "4. Summary Statistics and Numeric Functions in pandas\n",
    "\n",
    "Users also completed a basic data profiling exercise in Python which is a very common exercise performed by EY engagement teams. Python allows us to automate a traditionally manual and labor-intensive process. \n",
    "\n",
    "The section below provides links to other helpful resources that can be used to learn more about data handling in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Useful Resources\n",
    "- [pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
    "- [Quick pandas Tutorial](https://towardsdatascience.com/a-quick-introduction-to-the-pandas-python-library-f1b678f34673)\n",
    "- [pandas Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
